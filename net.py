import torch.nn as nn
from torch import tensor, add, sub
from typing import List
"""
Нейросети
"""

# Сигмоида входных нейронов А:
# Сигмоида: -2,5  -2      -1,5    -1      0,5     0       0,5     1       1,5     2       2,5
# Данные:   0     1       2       3       4       5       6       7       8       9       10
# Первое приближение: вертикальная посадка, только маршевый двигатель.

# Вариант 2.
# Состояние статуса 0 - двигатель выключен
# Ресурс 0 - топливо в баках двигателя закончилось
# Статус 3 означает, что двигатель будет ещё работать 3х5сек.
# В следующем проходе актора ресурс конкретного двигателя и статус двигателя уменьшаются на 1.
# Когда статус достигнет 0, ресурс уменьшаться перестаёт, и остаётся как есть до следующего включения двигателя
# Система управления двигатель не выключает. Включённый двигатель работает ровно столько, сколько запросила нейросеть
# актора.
# Входы актора:
# - 9 динамических параметров
# (положение по x, y [высота максимум 300 км]; скорость по x, y [максимально по x - 8000 м/с];
# ускорение по x, y; ориентация, угловая скорость, угловое ускорение)
# - 5 двигателей по 10 ресурсов (ресурс - максимально возможно время работы двигателя, от 0 до 10) - 50 шт.
# - 5 двигателей по 10 состояний статуса
# (статус - время работы двигателя по приказу НС в виде определённого состояния от 0 до 10) - 50 шт.
# - 1 Длительность до съёма следующих показаний, время в миллисекундах 0-1000
# - 1 Вход-индикатор работы миллисекундного входа, вкл / выкл
# - 1 Длительность до съёма следующих показаний, время в секундах, 0-1000
# - 1 Вход-индикатор работы секундного входа, вкл / выкл
# Примечание. Двойной вход на длительность по аналогии с палочками и колбочками глаза,
# которые работают в разных условиях освещённости.
# Выходы актора:
# - 5 двигателей по 10 состояний статуса - 50 шт.
# Входы критика:
# - 9 динамических параметров
# - 5 двигателей по 10 ресурсов - 50 шт.
# - 5 двигателей по 10 состояний статуса - 50 шт. - ВСЕ ВАРИАНТЫ, в рамках доступных ресурсов ~ 2500 вариантов.
# можно не считать варианты, по которым идёт превышение ресурсов.
# - 1 Длительность до съёма следующих показаний, время в миллисекундах 0-1000
# - 1 Вход-индикатор работы миллисекундного входа, вкл / выкл
# - 1 Длительность до съёма следующих показаний, время в секундах, 0-1000
# - 1 Вход-индикатор работы секундного входа, вкл / выкл
# Выход критика
# - 1 функция ценности

# Вариант 3.
# Входы в критика кроме ОС: по каждому двигателю на вход критика подаются два варианта (итого 10 входов по двигателям):
# двигатель включён и двигатель выключен. Затем производится выбор трёх максимальных функций ценности
# (три включённых / выключенных двигателя, дающих максимальную функцию ценности).
# Обучение критика и актора производится либо по максимальноё функции ценности, либо по усреднённому (по трём) значению.
# Получение подкрепления по тем же трём двигателям с максимальной функцией ценности. В этом случае, как ни крути,
# время работы одного двигателя должно быть кратно интервалу считывания показаний.

# Критерии оптимальности:
# - линейное ускорение на маршруте не более...
# - угловое ускорение на маршруте не более ...
# - Время на посадку: чем меньше, тем лучше. Возможно, лучше без данного критерия.
# Достаточно и мин. общего времени работы двигателей.
# - Минимальное общее время работы маршевого двигателя (экономия топлива)
# - Минимальное общее время работы рулевых двигателей (экономия топлива)
# - определённые линейные и угловые параметры ("не более") перед касанием земли

# Подкрепление.
# - Максимальное подкрепление при попадании в определённый диапазон у точки посадки по линейным и угловым параметрам.
# - Периодическое (с независимым постоянным временным интервалом) подкрепление на маршруте
# по факту нахождения в диапазоне линейных и угловых ускорений.
# - Периодическое (с независимым постоянным временным интервалом) подкрепление на маршруте
# по факту неработающих двигателей (а-ля зарплаты у Форда для ремонтной бригады)
# - В результате, после успешной посадки, подкрепления (возможно) по этим трём параметрам должны быть равными.

# Алгоритм обучения с подкреплением TD(0).
# 1. t. На вход актора подаётся состояние ОС s_t, на выходе актора имеем действие a_t.
# 2. t. ОС выдаёт подкрепление r_t на действие актора a_t в состоянии ОС s_t и новое состояние s_t+1
# 3. t. На вход критика подаётся состояние ОС s_t и действие актора a_t.
# 4. t. На выходе критика получаем функцию ценности действия Q_t(s_t, a_t) .
# 5. t+1. На вход актора подаётся состояние ОС s_t+1, на выходе актора имеем действие a_t+1.
# 6. t+1. ОС выдаёт подкрепление r_t+1 на действие актора a_t+1 в состоянии ОС s_t+1.
# 7. t+1. На вход критика подаётся состояние ОС s_t+1 и действие актора a_t+1.
# 8. t+1. На выходе критика получаем функцию ценности действия Q_t+1.
# 9. t+1. На основании Q_t, Q_t+1 и r_t+1, вычисляется корректировка dQ_t функции ценности действия Q_t.
# 10. t+1. Корректируем функцию Q_t на величину dQ_t, приближая её к реальности.
# В случае нейросетей, корректировкой является обратный проход по критику и далее по актору.
# Далее, в цикле, повторяем п. 5, 6, 7, 8, 9 для t+2, t+3, ..., t+n
# Примечания.
# 1. Подкрепление не является частью состояния окружающей среды.
# 2. Функция ценности действия в пределе выражает приведённую сумму всех подкреплений.

# Если критик уже обучен, то есть выдаёт с заданной точностью Q(s, a), то обучение актора выглядит так:
# 1. На вход критика последовательно подаются элементы множества {(s, a_1), (s, a_2), ..., (s, a_n)},
# где {a_1, a_2, ..., a_n} - множество вариантов действий актора в состоянии ОС s
# 2. Производится выбор такого действия актора, для которого Q_m(s, a_m) = max.
# 3. Производится обучение актора на основании выбранного действия a_m.

# А если критик ещё не обучен, как и актор?
# Всё то же самое, только ещё производится и обучение критика
# 1. На вход критика последовательно подаются элементы множества {(s, a_1), (s, a_2), ..., (s, a_n)}
# и на выходе критика последовательно получаем элементы множества Q = {Q_1, Q_2, ..., Q_n}
# 2. Выбираем из множества Q такое Q_m(s, a_m) = max
# 3. Обучаем критика на значении Q_m(s, a_m),
# вычисляя временнУю разницу с использованием подкрепления r_m для действия a_m.
# 4. ВременнАя разница, методом обратного распространения ошибки проводится через критика, и далее через актора.

# А если множество вариантов действий актора велико в одном состоянии ОС, или даже бесконечно?
# А если количество доступных состояний ОС является бесконечным?
# Это означает, что существует некое ограничение по точности функции Q(s, a). Это означает, что необходимо производить
# обучение актора и критика ВСЕГДА, даже при применении их в реальной практической работе.
# Так как выбор между разными вариантами действий в состоянии s может оказаться затруднённым или невозможным, видимо,
# придётся прибегнуть к некому последовательному движению по поверхности функции Q(s, a)
# в сторону её локального максимума через моменты времени t, t+1, t+2, ..., t+n:
# Q_t(s_t, a_t) -> Q_t+1(s_t+1, a_t+1) -> Q_t+2(s_t+2, a_t+2) -> Q_n(s_n, a_n) -> Q_n+1(s_n+1, a_n+1) = max
# Обдумать...
# Так как реальное обучение представляет из себя комбинацию действий актора a_m соответствующих Qmax
# и действий исследовательских, то, при неизвестном Qmax, бОльшая часть действий актора будет исследовательской
# (так как действия, фактически, выбираются случайно)


class Net(nn.Module):
    # todo устаревшее
    """
        Класс нейросети. Один универсальный класс-шаблон на исполнителя и на критика
    """
    # Модель нейросети:
    # Входной слой - слой нейронов
    # Секвенция скрытых слоёв состоящих из последовательных пар: Линейный слой - Нейронный слой
    # Выходной слой - линейный слой
    # Выходной слой нейронов
    # input_dimensions = 10
    def __init__(self,
                 input_dimensions: int,
                 hidden_dimensions: int,
                 output_dimensions: int,
                 layers_number: int,
                 initWeights = False):
        """
        :param input_dimensions: количество входов
        :param hidden_dimensions: количество нейронов в скрытом слое
        :param output_dimensions: количество выходов (классов)
        :param layers_number: количество слоёв
        :param initWeights: инициализировать веса или нет? Инициализацию надо производить ТОЛЬКО при создании NN
        """
        super(Net, self).__init__()

        self.__input_dimensions = input_dimensions
        self.__hidden_dimensions = hidden_dimensions
        self.__output_dimensions = output_dimensions
        self.__layers_number = layers_number

        # Семафор первого скрытого слоя
        # Если истина, то размерность входа для скрытого слоя равна размерности входя нейронной сети
        # В противном случае, размерность входа в скрытый слой, равна размерности скрытых слоёв
        self.__firstLayer = True

        # Туплю. Вроде создаётся объект. Но при прямом проходе происходит вызов одноимённой функции???
        self.__neuronIn = nn.Sigmoid()

        # массив из секвенций скрытых слоёв
        self.__hiddenLayersList = [self.__hiddenLayer() for i in range(self.__layers_number)]
        # преобразуем в общую секвенцию
        self.__hiddenLayers = nn.Sequential(*self.__hiddenLayersList)

        self.__linearHidden2Out = nn.Linear(self.__hidden_dimensions, self.__output_dimensions, bias=False)

        self.__neuronOut = nn.Sigmoid()

        if initWeights:
            self.__initializeWeights()

    def __hiddenLayer(self):
        '''
        Вспомогательная функция, возвращающая секвенцию слоя связей и слоя нейронов.
        :return:
        '''
        # первый проход функции - первый слой после входного
        dimension = self.__input_dimensions if self.__firstLayer else self.__hidden_dimensions
        self.__firstLayer = False

        return nn.Sequential(nn.Linear(dimension, self.__hidden_dimensions, bias=False),
                             nn.Sigmoid())

    def forward(self, x):
        """

        :param pr: входные данные (цены)
        :param rf: подкрепление
        :return:
        """
        x = self.__neuronIn(x)
        x = self.__hiddenLayers(x)
        x = self.__linearHidden2Out(x)
        x = self.__neuronOut(x)

        return x

    def __initializeWeights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.orthogonal_(m.weight)


class NetSeq(nn.Module):
    """ Нейросеть, собираемая из трёх секвенций. """
    def __init__(self, input: nn.Sequential, hidden: nn.Sequential, output: nn.Sequential,
                 initMethod=nn.init.orthogonal_, initWeights: bool = False):
        super(NetSeq, self).__init__()

        self._input = input
        self._hidden = hidden
        self._output = output
        self._initMethod = initMethod

        if initWeights:
            self.__initializeWeights()

    def forward(self, x):
        # super().forward()
        x = self._input(x)
        x = self._hidden(x)
        x = self._output(x)
        return x

    def __initializeWeights(self):
        """ Start initialization net weights. """
        for m in self.modules():
            #todo self.modules() возвращает модули всех секвенций нейросети? И входной, и скрытой, и выходной?
            if isinstance(m, nn.Linear):
                self._initMethod(m.weight)

    @classmethod
    def _create_sequence(cls, layers_list: List, repeat: int) -> nn.Sequential:
        layers = layers_list
        for count in range(repeat):
            layers = layers.extend(layers_list)
        return nn.Sequential(*layers)

    @classmethod
    def create_input(cls, layers_list: List) -> nn.Sequential:
        """ Create input net sequence (one neuron layer) """
        return NetSeq._create_sequence(layers_list, 1)

    @classmethod
    def create_hidden(cls, layer_list: List, repeat: int = 1) -> nn.Sequential:
        """ Create hidden layers sequence """
        return NetSeq._create_sequence(layer_list, repeat)

    @classmethod
    def create_output(cls, layer_list: List) -> nn.Sequential:
        """ Create output layers sequence. """
        return NetSeq._create_sequence(layer_list, 1)


# def tensorLoss(tensorOutput: tensor, tensorGrad: tensor):
#     """
#     Искусственное привнесение ошибки в тензор, для возможности обратного прохода.
#
#     :param tensorOutput:
#     :param tensorGrad:
#     :return:
#     """
#     # клон выходного тензора, без привязки к общему расчёту градиентов
#     clone = tensorOutput.clone().detach()
#     # независимый тензор складываем с градиентом / ошибкой (вносим ошибку в клон)
#     cloneWithGrad = add(clone, tensorGrad)
#     # из тензора с ошибкой вычитаем тензор без ошибки
#     result = sub(cloneWithGrad, tensorOutput)
#     # когда будем делать обратный проход по результату,
#     # дифференцирование пойдёт, с одной стороны tensorOutput (что нам и требуется)
#     # с другой стороны через клона (но он оторван от дерева рассчётов)
#     # и через тензор градиентов (но это тупиковый тензор)
#     return result
